{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RFIOXrPykfnw"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aHi-v1RVWXU7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def sigmoidDerivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def tanhDerivative(x):\n",
        "    return 1 - np.tanh(x)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R72_XSssWalT"
      },
      "outputs": [],
      "source": [
        "class LSTM:\n",
        "    def __init__(self, inputSize, hiddenSize, outputSize, learningRate=0.001):\n",
        "        self.inputSize = inputSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        self.outputSize = outputSize\n",
        "        self.learningRate = learningRate\n",
        "\n",
        "        self.weightForget = np.random.randn(hiddenSize, inputSize + hiddenSize) * 0.01\n",
        "        self.biasForget = np.zeros((hiddenSize, 1))\n",
        "\n",
        "        self.weightInput = np.random.randn(hiddenSize, inputSize + hiddenSize) * 0.01\n",
        "        self.biasInput = np.zeros((hiddenSize, 1))\n",
        "\n",
        "        self.weightCandidate = np.random.randn(hiddenSize, inputSize + hiddenSize) * 0.01\n",
        "        self.biasCandidate = np.zeros((hiddenSize, 1))\n",
        "\n",
        "        self.weightOutput = np.random.randn(hiddenSize, inputSize + hiddenSize) * 0.01\n",
        "        self.biasOutput = np.zeros((hiddenSize, 1))\n",
        "\n",
        "        self.weightY = np.random.randn(outputSize, hiddenSize) * 0.01\n",
        "        self.biasY = np.zeros((outputSize, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputVectors, hiddenStates, cellStates, outputs = {}, {}, {}, {}\n",
        "        forgetGates, inputGates, candidateValues, outputGates = {}, {}, {}, {}\n",
        "\n",
        "        hiddenStates[-1] = np.zeros((self.hiddenSize, 1))\n",
        "        cellStates[-1] = np.zeros((self.hiddenSize, 1))\n",
        "\n",
        "        for t in range(len(inputs)):\n",
        "            inputVectors[t] = np.zeros((self.inputSize, 1))\n",
        "            inputVectors[t][inputs[t]] = 1\n",
        "\n",
        "            concat = np.vstack((hiddenStates[t-1], inputVectors[t]))\n",
        "\n",
        "            forgetGates[t] = sigmoid(np.dot(self.weightForget, concat) + self.biasForget)\n",
        "            inputGates[t] = sigmoid(np.dot(self.weightInput, concat) + self.biasInput)\n",
        "            candidateValues[t] = tanh(np.dot(self.weightCandidate, concat) + self.biasCandidate)\n",
        "            cellStates[t] = forgetGates[t] * cellStates[t-1] + inputGates[t] * candidateValues[t]\n",
        "            outputGates[t] = sigmoid(np.dot(self.weightOutput, concat) + self.biasOutput)\n",
        "            hiddenStates[t] = outputGates[t] * tanh(cellStates[t])\n",
        "            outputs[t] = np.dot(self.weightY, hiddenStates[t]) + self.biasY\n",
        "\n",
        "        self.cache = (inputVectors, hiddenStates, cellStates, outputs, forgetGates, inputGates, candidateValues, outputGates)\n",
        "        return outputs\n",
        "    \n",
        "    def train(self, data, targets, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            loss = 0\n",
        "            self.forward(data)\n",
        "            self.backward(targets)\n",
        "\n",
        "            inputVectors, hiddenStates, cellStates, outputs, forgetGates, inputGates, candidateValues, outputGates = self.cache\n",
        "            for t in range(len(targets)):\n",
        "                expO = np.exp(outputs[t])\n",
        "                probs = expO / np.sum(expO)\n",
        "                loss += -np.log(probs[targets[t], 0])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "    def predict(self, seedIdx, nChars):\n",
        "        hidden = np.zeros((self.hiddenSize, 1))\n",
        "        cell = np.zeros((self.hiddenSize, 1))\n",
        "        inputVec = np.zeros((self.inputSize, 1))\n",
        "        inputVec[seedIdx] = 1\n",
        "        indices = []\n",
        "\n",
        "        for t in range(nChars):\n",
        "            concat = np.vstack((hidden, inputVec))\n",
        "            forgetGate = sigmoid(np.dot(self.weightForget, concat) + self.biasForget)\n",
        "            inputGate = sigmoid(np.dot(self.weightInput, concat) + self.biasInput)\n",
        "            candidateValue = tanh(np.dot(self.weightCandidate, concat) + self.biasCandidate)\n",
        "            cell = forgetGate * cell + inputGate * candidateValue\n",
        "            outputGate = sigmoid(np.dot(self.weightOutput, concat) + self.biasOutput)\n",
        "            hidden = outputGate * tanh(cell)\n",
        "            output = np.dot(self.weightY, hidden) + self.biasY\n",
        "\n",
        "            probs = np.exp(output) / np.sum(np.exp(output))\n",
        "            idx = np.random.choice(range(self.outputSize), p=probs.ravel())\n",
        "\n",
        "            inputVec = np.zeros((self.inputSize, 1))\n",
        "            inputVec[idx] = 1\n",
        "            indices.append(idx)\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def backward(self, targets):\n",
        "        inputVectors, hiddenStates, cellStates, outputs, forgetGates, inputGates, candidateValues, outputGates = self.cache\n",
        "\n",
        "        dWeightForget = np.zeros_like(self.weightForget)\n",
        "        dWeightInput = np.zeros_like(self.weightInput)\n",
        "        dWeightCandidate = np.zeros_like(self.weightCandidate)\n",
        "        dWeightOutput = np.zeros_like(self.weightOutput)\n",
        "        dWeightY = np.zeros_like(self.weightY)\n",
        "        dBiasForget = np.zeros_like(self.biasForget)\n",
        "        dBiasInput = np.zeros_like(self.biasInput)\n",
        "        dBiasCandidate = np.zeros_like(self.biasCandidate)\n",
        "        dBiasOutput = np.zeros_like(self.biasOutput)\n",
        "        dBiasY = np.zeros_like(self.biasY)\n",
        "\n",
        "        dHiddenNext = np.zeros_like(hiddenStates[0])\n",
        "        dCellNext = np.zeros_like(cellStates[0])\n",
        "\n",
        "        for t in reversed(range(len(targets))):\n",
        "            concat = np.vstack((hiddenStates[t-1], inputVectors[t]))\n",
        "\n",
        "            expO = np.exp(outputs[t])\n",
        "            probs = expO / np.sum(expO)\n",
        "            dOutput = probs.copy()\n",
        "            dOutput[targets[t]] -= 1\n",
        "\n",
        "            dWeightY += np.dot(dOutput, hiddenStates[t].T)\n",
        "            dBiasY += dOutput\n",
        "\n",
        "            dHidden = np.dot(self.weightY.T, dOutput) + dHiddenNext\n",
        "\n",
        "            tanhCell = np.tanh(cellStates[t])\n",
        "            dOutputGate = dHidden * tanhCell\n",
        "            dCell = dHidden * outputGates[t] * (1 - tanhCell ** 2) + dCellNext\n",
        "\n",
        "            dForgetGate = dCell * cellStates[t-1]\n",
        "            dInputGate = dCell * candidateValues[t]\n",
        "            dCandidateValue = dCell * inputGates[t]\n",
        "            dOutputGateRaw = dOutputGate * outputGates[t] * (1 - outputGates[t])\n",
        "            dForgetGateRaw = dForgetGate * forgetGates[t] * (1 - forgetGates[t])\n",
        "            dInputGateRaw = dInputGate * inputGates[t] * (1 - inputGates[t])\n",
        "            dCandidateValueRaw = dCandidateValue * (1 - candidateValues[t] ** 2)\n",
        "\n",
        "            dWeightForget += np.dot(dForgetGateRaw, concat.T)\n",
        "            dWeightInput += np.dot(dInputGateRaw, concat.T)\n",
        "            dWeightCandidate += np.dot(dCandidateValueRaw, concat.T)\n",
        "            dWeightOutput += np.dot(dOutputGateRaw, concat.T)\n",
        "            dBiasForget += dForgetGateRaw\n",
        "            dBiasInput += dInputGateRaw\n",
        "            dBiasCandidate += dCandidateValueRaw\n",
        "            dBiasOutput += dOutputGateRaw\n",
        "\n",
        "            dConcat = np.dot(self.weightForget.T, dForgetGateRaw) + np.dot(self.weightInput.T, dInputGateRaw) + np.dot(self.weightCandidate.T, dCandidateValueRaw) + np.dot(self.weightOutput.T, dOutputGateRaw)\n",
        "\n",
        "            dHiddenNext = dConcat[:self.hiddenSize]\n",
        "            dCellNext = dCell * forgetGates[t]\n",
        "\n",
        "        for param, dparam in zip([self.weightForget, self.weightInput, self.weightCandidate, self.weightOutput, self.weightY,\n",
        "                                  self.biasForget, self.biasInput, self.biasCandidate, self.biasOutput, self.biasY],\n",
        "                                [dWeightForget, dWeightInput, dWeightCandidate, dWeightOutput, dWeightY,\n",
        "                                 dBiasForget, dBiasInput, dBiasCandidate, dBiasOutput, dBiasY]):\n",
        "            np.clip(dparam, -5, 5, out=dparam)\n",
        "            param -= self.learningRate * dparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 914.1107098053038\n",
            "\n",
            "Trend for Kanyon:\n",
            "     invoice_date     sales\n",
            "4      2021-01-01  58495.73\n",
            "14     2021-01-02  56415.39\n",
            "24     2021-01-03  81463.92\n",
            "34     2021-01-04  75300.34\n",
            "44     2021-01-05  50942.92\n",
            "...           ...       ...\n",
            "7917   2023-03-04  94853.13\n",
            "7927   2023-03-05  43080.33\n",
            "7937   2023-03-06  93314.76\n",
            "7947   2023-03-07  22907.25\n",
            "7957   2023-03-08  83303.46\n",
            "\n",
            "[797 rows x 2 columns]\n",
            "Predicted: [np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(28358.835499999997), np.float64(123354.41449999997), np.float64(14788.038499999999), np.float64(96212.82049999997), np.float64(55500.429499999984), np.float64(96212.82049999997), np.float64(41929.63249999999), np.float64(109783.61749999998), np.float64(69071.22649999999), np.float64(14788.038499999999), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(96212.82049999997), np.float64(69071.22649999999), np.float64(55500.429499999984), np.float64(14788.038499999999), np.float64(136925.21149999998), np.float64(55500.429499999984), np.float64(109783.61749999998), np.float64(28358.835499999997), np.float64(41929.63249999999), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(69071.22649999999), np.float64(41929.63249999999), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(41929.63249999999), np.float64(14788.038499999999), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(96212.82049999997), np.float64(41929.63249999999), np.float64(136925.21149999998), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(28358.835499999997), np.float64(136925.21149999998), np.float64(109783.61749999998), np.float64(109783.61749999998), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(123354.41449999997), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(69071.22649999999), np.float64(41929.63249999999), np.float64(28358.835499999997), np.float64(55500.429499999984), np.float64(28358.835499999997), np.float64(41929.63249999999), np.float64(69071.22649999999), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(109783.61749999998), np.float64(69071.22649999999), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(55500.429499999984), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(96212.82049999997), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(136925.21149999998), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(14788.038499999999), np.float64(109783.61749999998), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(96212.82049999997), np.float64(69071.22649999999), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(109783.61749999998), np.float64(136925.21149999998), np.float64(69071.22649999999), np.float64(28358.835499999997), np.float64(96212.82049999997), np.float64(41929.63249999999), np.float64(69071.22649999999), np.float64(69071.22649999999), np.float64(55500.429499999984), np.float64(41929.63249999999), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(41929.63249999999), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(96212.82049999997), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(69071.22649999999), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(14788.038499999999), np.float64(41929.63249999999), np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(69071.22649999999), np.float64(109783.61749999998), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(69071.22649999999), np.float64(41929.63249999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(69071.22649999999), np.float64(96212.82049999997), np.float64(123354.41449999997), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(96212.82049999997), np.float64(96212.82049999997), np.float64(41929.63249999999), np.float64(109783.61749999998), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(136925.21149999998), np.float64(69071.22649999999), np.float64(14788.038499999999), np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(41929.63249999999), np.float64(109783.61749999998), np.float64(109783.61749999998), np.float64(109783.61749999998), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(28358.835499999997), np.float64(96212.82049999997), np.float64(69071.22649999999), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(41929.63249999999), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(14788.038499999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(28358.835499999997), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(69071.22649999999), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(69071.22649999999), np.float64(109783.61749999998), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(41929.63249999999), np.float64(14788.038499999999), np.float64(136925.21149999998), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(96212.82049999997), np.float64(28358.835499999997), np.float64(14788.038499999999), np.float64(28358.835499999997), np.float64(28358.835499999997), np.float64(14788.038499999999), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(41929.63249999999), np.float64(28358.835499999997), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(55500.429499999984), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(41929.63249999999), np.float64(55500.429499999984), np.float64(69071.22649999999), np.float64(136925.21149999998), np.float64(14788.038499999999), np.float64(69071.22649999999), np.float64(55500.429499999984), np.float64(96212.82049999997), np.float64(28358.835499999997), np.float64(55500.429499999984), np.float64(69071.22649999999), np.float64(69071.22649999999), np.float64(14788.038499999999), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(14788.038499999999), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(123354.41449999997), np.float64(96212.82049999997), np.float64(28358.835499999997), np.float64(14788.038499999999), np.float64(28358.835499999997), np.float64(109783.61749999998), np.float64(69071.22649999999), np.float64(28358.835499999997), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(28358.835499999997), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(82642.02349999998), np.float64(69071.22649999999), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(82642.02349999998), np.float64(109783.61749999998), np.float64(41929.63249999999), np.float64(82642.02349999998), np.float64(96212.82049999997), np.float64(123354.41449999997), np.float64(96212.82049999997), np.float64(109783.61749999998), np.float64(69071.22649999999), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(69071.22649999999), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(96212.82049999997), np.float64(109783.61749999998), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(28358.835499999997), np.float64(82642.02349999998), np.float64(109783.61749999998), np.float64(109783.61749999998), np.float64(69071.22649999999), np.float64(14788.038499999999), np.float64(55500.429499999984), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(96212.82049999997), np.float64(55500.429499999984), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(109783.61749999998), np.float64(96212.82049999997), np.float64(109783.61749999998), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(82642.02349999998), np.float64(28358.835499999997), np.float64(123354.41449999997), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(82642.02349999998), np.float64(96212.82049999997), np.float64(41929.63249999999), np.float64(82642.02349999998), np.float64(14788.038499999999), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(96212.82049999997), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(41929.63249999999), np.float64(109783.61749999998), np.float64(28358.835499999997), np.float64(14788.038499999999), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(69071.22649999999), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(136925.21149999998), np.float64(96212.82049999997), np.float64(109783.61749999998), np.float64(14788.038499999999), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(41929.63249999999), np.float64(14788.038499999999), np.float64(69071.22649999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(123354.41449999997), np.float64(82642.02349999998), np.float64(109783.61749999998), np.float64(55500.429499999984), np.float64(14788.038499999999), np.float64(82642.02349999998), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(82642.02349999998), np.float64(82642.02349999998), np.float64(55500.429499999984), np.float64(136925.21149999998), np.float64(123354.41449999997), np.float64(96212.82049999997), np.float64(136925.21149999998), np.float64(28358.835499999997), np.float64(123354.41449999997), np.float64(109783.61749999998), np.float64(123354.41449999997), np.float64(136925.21149999998), np.float64(69071.22649999999), np.float64(69071.22649999999), np.float64(41929.63249999999), np.float64(28358.835499999997), np.float64(41929.63249999999), np.float64(55500.429499999984), np.float64(123354.41449999997), np.float64(96212.82049999997)]\n",
            "Actual: [ 65172.03  46648.24  79523.08  45662.05  56335.46  53683.82 115645.04\n",
            "  74988.33 111928.19  37619.45  56915.91  66361.76  78444.45  28160.1\n",
            "  32790.1   40457.57  87469.65  25799.96  97181.07  68982.93  89826.38\n",
            "  36128.21  35214.78  41503.87  39557.78  61735.73  47949.81  11083.28\n",
            "  81089.04  36926.67  41727.16 110701.45  37433.35  45177.82  41570.06\n",
            " 134233.08  73363.18  56837.78  71545.48  87572.63  67471.04  81450.12\n",
            "  69880.75  34526.06 115390.75  62929.89  99887.38  83326.42  54459.95\n",
            "  54138.1   78576.46  95594.36  76546.99  42077.74  21726.76  47693.12\n",
            "  29924.49  66475.12  59536.62  71396.01  71938.84  39801.48  50664.03\n",
            "  65442.63  50233.17  40791.6   26294.4  103657.44  58823.78  48942.14\n",
            "  94848.03  46007.03  43189.64  52954.52  84919.36  16873.07  56093.47\n",
            " 124491.84  79709.32  43160.49 108524.86  46835.82  73588.71  53190.58\n",
            "  56814.32  75712.49  83124.5   65996.24  96621.97  53130.88  70848.06\n",
            "  40261.67  56820.59  28955.34  96764.92  51532.94  52716.65  66740.23\n",
            "  64142.27  52054.78  46239.53  46492.72 135019.17  55064.92  78927.6\n",
            "  42632.53 102359.2   30091.88  62747.16  24482.02  73576.13  48335.69\n",
            "  84755.1   30599.9   68160.72  63302.11  75586.47  69349.11  46897.14\n",
            "  52196.55  68447.29 119646.25  82832.76  63647.66  43249.48  50479.21\n",
            "  85625.25  40294.95  70549.07  78099.02 107657.77  48472.4   24028.72\n",
            "  61054.59  36211.27  67685.01  47209.02  76593.64  86093.67  66777.9\n",
            "  63630.73  89358.95  74521.45  40393.42  62017.74  34879.16  69868.2\n",
            "  95656.24  72205.14  40312.86  82786.53 107146.68  60507.12  55180.98\n",
            "  45909.56 102492.32  46935.92  36577.35  66970.67  74503.42  53667.37\n",
            " 122895.81  66682.31  43815.56  71436.08  63698.29  76097.73  62018.34\n",
            "  49653.28  72366.03  45221.91  38661.42  98423.9  121023.57  71774.22\n",
            "  30035.4   70271.18  45216.11  62930.75  79675.64  73782.41 108761.44\n",
            "  84100.67  94077.82  63032.09  44462.08  46765.72 109022.85  81584.37\n",
            "  60489.5   55058.01  45215.32  73153.23  58227.26  63714.11  85302.37\n",
            "  42580.35  20870.49  22740.52  31425.82  76210.4   73058.78  46224.39\n",
            "  70092.93  70935.31  80636.72  55506.2   60214.05  33939.99  58160.81\n",
            "  80367.28  70279.1   51242.32  59136.86  47651.82  92193.85  16854.92\n",
            "  68375.57  88078.68  66371.9   71696.09  34570.39  73988.18  64727.93\n",
            "  41388.   114792.22  99803.78  83401.75  47437.51  59347.98  57090.39\n",
            "  30024.03  52317.27  41445.2   27757.8   49559.68  76670.31  45456.81\n",
            "  32602.91  28735.71  66180.16  68075.49  76806.9   60105.9   87302.43\n",
            "  59010.12  39484.39  76484.95  84886.14  39463.86  89239.45  50576.71\n",
            "  82531.52  58907.   108619.09  60546.91 129945.34  31622.3   68427.12\n",
            "  33239.9   92150.19  58978.87  61889.07  38138.7   76726.36  97767.22\n",
            " 102315.65  90132.47  15454.53  77008.41  76877.42  90004.35  42210.83\n",
            "  71332.6   38660.17  93007.13  67555.82  58426.44  19694.74  57335.91\n",
            "  63403.46  25898.93  49904.97  63168.24  60146.4   40591.6   55814.19\n",
            " 142112.45  46749.34  21600.87  19317.93  97337.3   49883.43   8002.64\n",
            "  85300.1   52029.45  95628.35  46571.63  49841.98  47325.23  74305.57\n",
            "  44243.39  46376.56  50791.08  71765.58 143710.61  68562.57  37239.72\n",
            "  41713.07  96086.77 100431.84  98769.03  35970.99  46630.23  38828.38\n",
            "  39466.87  41533.85  49526.86  91301.36  97378.51  93877.36  38629.72\n",
            "  86064.33  32815.37  43320.71  85651.05  76403.32  80958.05  45438.94\n",
            " 103851.11  36373.03  31782.1   99223.43  51590.27  71471.88  73790.68\n",
            "  51305.3   73715.4   66737.48 111408.    74578.72 102074.49  23210.85\n",
            "  82868.38  35586.64  89778.36  45283.01  88663.9   37450.25  59473.81\n",
            "  29924.04  44823.16  75820.31  65981.86  38003.61  67769.13  25828.45\n",
            " 101670.59  69582.13  43596.68  77699.09  34388.07  73098.33  69936.48\n",
            " 123742.87  30706.59  85703.08  69341.45  75042.42  50221.06  67518.56\n",
            "  62275.89  61166.49  36108.12  51616.37  63978.61  91300.7   94318.51\n",
            "  34146.28  85476.25  80441.76  76469.72 113956.4   86839.69  34158.92\n",
            "  33001.55  84222.57  99370.74  65004.79  84154.28  47324.56  83026.45\n",
            "  43773.61  55614.72  94853.13  43080.33  93314.76  22907.25  83303.46]\n",
            "Epoch 0, Loss: 911.809247388421\n",
            "\n",
            "Trend for Forum Istanbul:\n",
            "     invoice_date     sales\n",
            "2      2021-01-01   4522.56\n",
            "12     2021-01-02  16880.49\n",
            "22     2021-01-03  18989.21\n",
            "32     2021-01-04  17683.83\n",
            "42     2021-01-05  22842.09\n",
            "...           ...       ...\n",
            "7915   2023-03-04   1896.37\n",
            "7925   2023-03-05   7215.68\n",
            "7935   2023-03-06  50821.05\n",
            "7945   2023-03-07  16325.87\n",
            "7955   2023-03-08  31321.35\n",
            "\n",
            "[795 rows x 2 columns]\n",
            "Predicted: [np.float64(30358.591999999997), np.float64(63991.572), np.float64(23631.996), np.float64(63991.572), np.float64(16905.4), np.float64(16905.4), np.float64(23631.996), np.float64(23631.996), np.float64(43811.784), np.float64(50538.380000000005), np.float64(37085.188), np.float64(10178.804), np.float64(50538.380000000005), np.float64(57264.975999999995), np.float64(30358.591999999997), np.float64(57264.975999999995), np.float64(16905.4), np.float64(3452.2079999999996), np.float64(30358.591999999997), np.float64(57264.975999999995), np.float64(16905.4), np.float64(3452.2079999999996), np.float64(16905.4), np.float64(43811.784), np.float64(30358.591999999997), np.float64(37085.188), np.float64(43811.784), np.float64(63991.572), np.float64(10178.804), np.float64(50538.380000000005), np.float64(37085.188), np.float64(63991.572), np.float64(43811.784), np.float64(57264.975999999995), np.float64(3452.2079999999996), np.float64(10178.804), np.float64(3452.2079999999996), np.float64(10178.804), np.float64(43811.784), np.float64(43811.784), np.float64(43811.784), np.float64(10178.804), np.float64(30358.591999999997), np.float64(37085.188), np.float64(57264.975999999995), np.float64(10178.804), np.float64(50538.380000000005), np.float64(57264.975999999995), np.float64(16905.4), np.float64(63991.572), np.float64(63991.572), np.float64(57264.975999999995), np.float64(37085.188), np.float64(3452.2079999999996), np.float64(16905.4), np.float64(43811.784), np.float64(10178.804), np.float64(50538.380000000005), np.float64(63991.572), np.float64(3452.2079999999996), np.float64(23631.996), np.float64(10178.804), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(63991.572), np.float64(57264.975999999995), np.float64(57264.975999999995), np.float64(30358.591999999997), np.float64(37085.188), np.float64(43811.784), np.float64(10178.804), np.float64(57264.975999999995), np.float64(63991.572), np.float64(30358.591999999997), np.float64(43811.784), np.float64(10178.804), np.float64(57264.975999999995), np.float64(3452.2079999999996), np.float64(50538.380000000005), np.float64(30358.591999999997), np.float64(16905.4), np.float64(37085.188), np.float64(37085.188), np.float64(50538.380000000005), np.float64(43811.784), np.float64(57264.975999999995), np.float64(37085.188), np.float64(57264.975999999995), np.float64(37085.188), np.float64(16905.4), np.float64(3452.2079999999996), np.float64(37085.188), np.float64(50538.380000000005), np.float64(16905.4), np.float64(16905.4), np.float64(10178.804), np.float64(63991.572), np.float64(50538.380000000005), np.float64(37085.188), np.float64(57264.975999999995), np.float64(10178.804), np.float64(16905.4), np.float64(23631.996), np.float64(10178.804), np.float64(37085.188), np.float64(16905.4), np.float64(3452.2079999999996), np.float64(16905.4), np.float64(10178.804), np.float64(23631.996), np.float64(43811.784), np.float64(10178.804), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(3452.2079999999996), np.float64(30358.591999999997), np.float64(23631.996), np.float64(16905.4), np.float64(43811.784), np.float64(30358.591999999997), np.float64(16905.4), np.float64(10178.804), np.float64(57264.975999999995), np.float64(23631.996), np.float64(50538.380000000005), np.float64(16905.4), np.float64(30358.591999999997), np.float64(37085.188), np.float64(57264.975999999995), np.float64(10178.804), np.float64(43811.784), np.float64(63991.572), np.float64(57264.975999999995), np.float64(50538.380000000005), np.float64(57264.975999999995), np.float64(23631.996), np.float64(10178.804), np.float64(37085.188), np.float64(10178.804), np.float64(57264.975999999995), np.float64(63991.572), np.float64(50538.380000000005), np.float64(37085.188), np.float64(23631.996), np.float64(10178.804), np.float64(43811.784), np.float64(37085.188), np.float64(23631.996), np.float64(30358.591999999997), np.float64(43811.784), np.float64(57264.975999999995), np.float64(16905.4), np.float64(37085.188), np.float64(30358.591999999997), np.float64(43811.784), np.float64(43811.784), np.float64(16905.4), np.float64(23631.996), np.float64(50538.380000000005), np.float64(30358.591999999997), np.float64(63991.572), np.float64(43811.784), np.float64(57264.975999999995), np.float64(30358.591999999997), np.float64(3452.2079999999996), np.float64(43811.784), np.float64(50538.380000000005), np.float64(3452.2079999999996), np.float64(50538.380000000005), np.float64(50538.380000000005), np.float64(30358.591999999997), np.float64(30358.591999999997), np.float64(16905.4), np.float64(10178.804), np.float64(30358.591999999997), np.float64(43811.784), np.float64(30358.591999999997), np.float64(10178.804), np.float64(30358.591999999997), np.float64(10178.804), np.float64(10178.804), np.float64(37085.188), np.float64(23631.996), np.float64(10178.804), np.float64(37085.188), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(23631.996), np.float64(50538.380000000005), np.float64(23631.996), np.float64(43811.784), np.float64(63991.572), np.float64(16905.4), np.float64(10178.804), np.float64(23631.996), np.float64(30358.591999999997), np.float64(16905.4), np.float64(63991.572), np.float64(57264.975999999995), np.float64(23631.996), np.float64(43811.784), np.float64(30358.591999999997), np.float64(63991.572), np.float64(50538.380000000005), np.float64(57264.975999999995), np.float64(43811.784), np.float64(10178.804), np.float64(16905.4), np.float64(43811.784), np.float64(30358.591999999997), np.float64(43811.784), np.float64(43811.784), np.float64(57264.975999999995), np.float64(16905.4), np.float64(50538.380000000005), np.float64(37085.188), np.float64(37085.188), np.float64(10178.804), np.float64(10178.804), np.float64(50538.380000000005), np.float64(50538.380000000005), np.float64(37085.188), np.float64(50538.380000000005), np.float64(30358.591999999997), np.float64(30358.591999999997), np.float64(10178.804), np.float64(10178.804), np.float64(3452.2079999999996), np.float64(57264.975999999995), np.float64(43811.784), np.float64(43811.784), np.float64(23631.996), np.float64(37085.188), np.float64(57264.975999999995), np.float64(50538.380000000005), np.float64(37085.188), np.float64(10178.804), np.float64(37085.188), np.float64(23631.996), np.float64(10178.804), np.float64(30358.591999999997), np.float64(23631.996), np.float64(57264.975999999995), np.float64(23631.996), np.float64(50538.380000000005), np.float64(3452.2079999999996), np.float64(37085.188), np.float64(10178.804), np.float64(50538.380000000005), np.float64(23631.996), np.float64(16905.4), np.float64(16905.4), np.float64(50538.380000000005), np.float64(43811.784), np.float64(43811.784), np.float64(3452.2079999999996), np.float64(10178.804), np.float64(30358.591999999997), np.float64(16905.4), np.float64(16905.4), np.float64(23631.996), np.float64(43811.784), np.float64(30358.591999999997), np.float64(37085.188), np.float64(43811.784), np.float64(43811.784), np.float64(3452.2079999999996), np.float64(30358.591999999997), np.float64(57264.975999999995), np.float64(16905.4), np.float64(30358.591999999997), np.float64(63991.572), np.float64(16905.4), np.float64(30358.591999999997), np.float64(10178.804), np.float64(57264.975999999995), np.float64(10178.804), np.float64(23631.996), np.float64(23631.996), np.float64(43811.784), np.float64(16905.4), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(63991.572), np.float64(10178.804), np.float64(57264.975999999995), np.float64(16905.4), np.float64(3452.2079999999996), np.float64(3452.2079999999996), np.float64(23631.996), np.float64(43811.784), np.float64(57264.975999999995), np.float64(37085.188), np.float64(50538.380000000005), np.float64(37085.188), np.float64(43811.784), np.float64(10178.804), np.float64(16905.4), np.float64(63991.572), np.float64(23631.996), np.float64(10178.804), np.float64(30358.591999999997), np.float64(50538.380000000005), np.float64(37085.188), np.float64(23631.996), np.float64(23631.996), np.float64(37085.188), np.float64(43811.784), np.float64(30358.591999999997), np.float64(10178.804), np.float64(43811.784), np.float64(30358.591999999997), np.float64(37085.188), np.float64(43811.784), np.float64(16905.4), np.float64(57264.975999999995), np.float64(30358.591999999997), np.float64(43811.784), np.float64(37085.188), np.float64(37085.188), np.float64(43811.784), np.float64(16905.4), np.float64(30358.591999999997), np.float64(63991.572), np.float64(23631.996), np.float64(30358.591999999997), np.float64(23631.996), np.float64(37085.188), np.float64(57264.975999999995), np.float64(30358.591999999997), np.float64(43811.784), np.float64(10178.804), np.float64(50538.380000000005), np.float64(37085.188), np.float64(10178.804), np.float64(43811.784), np.float64(43811.784), np.float64(16905.4), np.float64(50538.380000000005), np.float64(30358.591999999997), np.float64(37085.188), np.float64(3452.2079999999996), np.float64(57264.975999999995), np.float64(3452.2079999999996), np.float64(50538.380000000005), np.float64(63991.572), np.float64(37085.188), np.float64(23631.996), np.float64(23631.996), np.float64(10178.804), np.float64(23631.996), np.float64(43811.784), np.float64(63991.572), np.float64(37085.188), np.float64(3452.2079999999996), np.float64(63991.572), np.float64(3452.2079999999996), np.float64(50538.380000000005), np.float64(57264.975999999995), np.float64(50538.380000000005), np.float64(50538.380000000005), np.float64(43811.784), np.float64(37085.188), np.float64(50538.380000000005), np.float64(3452.2079999999996), np.float64(63991.572), np.float64(3452.2079999999996), np.float64(16905.4), np.float64(30358.591999999997), np.float64(43811.784), np.float64(43811.784), np.float64(16905.4), np.float64(43811.784), np.float64(3452.2079999999996), np.float64(57264.975999999995), np.float64(37085.188), np.float64(3452.2079999999996), np.float64(30358.591999999997), np.float64(3452.2079999999996), np.float64(37085.188), np.float64(63991.572), np.float64(37085.188), np.float64(50538.380000000005), np.float64(43811.784), np.float64(30358.591999999997), np.float64(10178.804), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(10178.804), np.float64(16905.4), np.float64(10178.804), np.float64(57264.975999999995), np.float64(23631.996), np.float64(3452.2079999999996), np.float64(30358.591999999997), np.float64(37085.188), np.float64(57264.975999999995), np.float64(3452.2079999999996)]\n",
            "Actual: [19593.3   8116.25 36545.42 15809.75 18415.79  4245.75   568.3   9489.41\n",
            "  4287.94 17879.3  20312.11 13972.24 30093.55  6058.37  5798.95 34577.56\n",
            "  6048.67  6229.68  1850.88 18402.69 28933.36 40297.3  18615.04 25140.24\n",
            "  7502.    5813.76   246.32  3294.17 21389.74 19896.7    914.34 21389.19\n",
            " 15713.13 24342.36 23969.76  3879.86 25464.07  8764.54  1834.44 25787.68\n",
            " 23858.67 32594.45 19089.39 15364.93 40981.54 22841.77 13809.09  2216.82\n",
            " 28573.84   230.94 15218.68  1055.24  1369.83 31667.71  5028.66 15140.07\n",
            " 10661.44 16310.62 12181.19 24373.26 21781.35   310.72 32400.76 15221.78\n",
            " 33359.22  2237.14  1097.04 33877.94  1087.9  10456.98 31420.76 34408.17\n",
            " 29407.84 11464.7  16666.82 25626.14 28073.65  9344.64 21149.04 29702.98\n",
            "  1403.52  5457.92 31964.7  22528.73  4600.99 23911.31  8102.17 44796.01\n",
            " 31391.77 21066.2  10669.59  2966.24 17516.98 14896.14 11817.27  6042.26\n",
            " 22730.47 23905.83 17834.56 11294.2  12008.43 26879.61 46809.51  9961.8\n",
            "  5195.84 44285.12 18467.48  7305.21 11537.67  1003.04 57595.52   901.23\n",
            "  9949.75  5357.71 59784.29  7399.69  8726.    2679.88 15681.98  7502.\n",
            " 12092.96   347.15  2400.68 12454.95 23632.56 23298.01 22754.58 30799.34\n",
            " 16192.21 10776.24  9238.17  2216.82  5740.72 34009.39    88.91 31411.63\n",
            "   767.74 31193.55  7664.64 10225.36 11146.36 18079.76 20366.9  24933.2\n",
            " 17976.24  5345.8  14486.4  36906.55  2828.16 24247.03 37932.51 13080.08\n",
            " 26274.52 14853.86 46017.89 25216.84  6442.74 22872.19 19805.28  3297.43\n",
            " 16407.87 22846.99 28704.44  5225.17  9806.19  7795.25  2589.93  2510.87\n",
            " 26012.36   743.53 37654.08 16053.17 20977.76  9145.33  5401.53 13850.6\n",
            "  9214.94 13791.84 26066.79  9635.3   7607.57  8065.4   9895.34 20057.67\n",
            "  1272.16 32927.25 11508.91  6516.56  5262.63 11593.88 12308.51 15811.7\n",
            " 40427.3   4662.72  2134.44 26064.02 22378.32 12743.45  7802.08 15275.32\n",
            " 18046.82  4247.28 27097.34 17159.91 10005.68 17220.82 11570.49 27907.73\n",
            " 12089.48  2216.82 17770.87  1605.95 24584.75  3902.39  5467.36 24817.02\n",
            " 25585.72  4067.63 36579.1  42357.29 13403.19 14551.53 27962.93 18920.3\n",
            "  1118.51  9623.64 12418.22  6937.68  8116.1   1812.68  3947.96 11506.74\n",
            " 19677.99  4429.33 12352.45 20461.36 22748.44 16025.89  3217.21  9985.65\n",
            " 49618.29 27447.68  8864.48 16409.86 35968.82  1397.62  1293.21 29124.89\n",
            " 20125.12 17187.21 16774.22  5385.15 27052.35 19886.44  3757.88 20807.47\n",
            "   634.04  2590.35 37250.12  1627.88 48937.91 27960.82 16916.5   7953.84\n",
            " 45631.88 34024.92 16468.01 19952.84 16654.19  6677.08  2166.4  13503.61\n",
            " 17044.66  3329.6  13550.77  2148.66 11126.24 61960.51 40627.4  16728.93\n",
            "  1584.3  15829.7  19081.31 27003.21 16685.91 11485.85  8773.59  3180.82\n",
            "  5444.92 21090.72  8837.11  1357.24 12622.42 15546.01  7802.08 24902.1\n",
            " 16061.41  8243.31 29901.92 21850.66 12074.52 10890.69 18970.9   3696.51\n",
            "   467.44  2527.51  1089.97  7507.23  2412.51 28962.11 25786.39  7970.64\n",
            "  7574.88  2841.16  7502.   23262.62 12635.89  8257.16 25187.47 19998.45\n",
            "  3196.23 11341.12 22555.43 11971.42 11663.8   1019.58 27313.55  7802.08\n",
            "  9703.71 12912.56 32995.12   479.28  9833.48 18064.3  38489.8  19097.22\n",
            " 15282.94 21056.04 21521.56  6376.15  1930.32  9191.92 15654.56 13795.92\n",
            " 13490.53 20613.75 15475.51  1428.49  6504.11  5073.26 10899.64 10365.39\n",
            "  5365.36  9412.11 31051.28  3810.45  4404.16  4573.18 14117.51 12797.22\n",
            "  4944.64 22932.65  5964.42 23899.42  8890.    3577.91 15213.71  5101.36\n",
            " 17684.32  1859.39   629.03 21617.58  5512.77  4990.53 51457.45 53853.37\n",
            "  9811.78  3111.18 16713.5  43132.87 21080.28 12113.73 11931.25 11304.92\n",
            "  1056.8  23190.56 14527.27 11224.26 10137.12 18241.38  8250.8  10489.27\n",
            " 15723.77  1896.37  7215.68 50821.05 16325.87 31321.35]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"custdata.csv\")\n",
        "\n",
        "df = df.drop(['invoice_no', 'customer_id', 'category'], axis=1)\n",
        "df['sales'] = df['quantity'] * df['price']\n",
        "df['invoice_date'] = pd.to_datetime(df['invoice_date'], format='%d/%m/%Y')\n",
        "\n",
        "dailySales = df.groupby(['invoice_date', 'shopping_mall'])['sales'].sum().reset_index()\n",
        "\n",
        "malls = ['Kanyon', 'Forum Istanbul']\n",
        "numBins = 10\n",
        "\n",
        "for mall in malls:\n",
        "    mallData = dailySales[dailySales['shopping_mall'] == mall].sort_values('invoice_date')\n",
        "    sales = mallData['sales'].values\n",
        "    \n",
        "    salesMin, salesMax = sales.min(), sales.max()\n",
        "    binEdges = np.linspace(salesMin, salesMax, numBins + 1)\n",
        "    \n",
        "    def getBin(value):\n",
        "        return min(max(np.digitize(value, binEdges) - 1, 0), numBins - 1)\n",
        "    \n",
        "    sequence = [getBin(s) for s in sales]\n",
        "    \n",
        "    n = len(sequence)\n",
        "    trainEnd = n // 2\n",
        "    trainSeq = sequence[:trainEnd]\n",
        "    \n",
        "    data = trainSeq[:-1]\n",
        "    targets = trainSeq[1:]\n",
        "    \n",
        "    model = LSTM(numBins, 128, numBins, 0.001)\n",
        "    model.train(data, targets, epochs=10)\n",
        "    \n",
        "    predLength = n - trainEnd\n",
        "    predictedBins = model.predict(trainSeq[-1], predLength)\n",
        "    \n",
        "    def binToSales(b):\n",
        "        return (binEdges[b] + binEdges[b + 1]) / 2\n",
        "    \n",
        "    predictedSales = [binToSales(b) for b in predictedBins]\n",
        "    actualSales = sales[trainEnd:]\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    dates = mallData['invoice_date'].values\n",
        "    plt.figure()\n",
        "    plt.plot(dates, sales)\n",
        "    plt.plot(dates[trainEnd:], predictedSales)\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
